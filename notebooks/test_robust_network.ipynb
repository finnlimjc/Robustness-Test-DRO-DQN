{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e7d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef669ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.agent import *\n",
    "from src.agent_interface import *\n",
    "from src.prior_measure import *\n",
    "from src.robust import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddcbdddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da71391f",
   "metadata": {},
   "source": [
    "# Training Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aedfed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = 5\n",
    "clone_steps = 50\n",
    "batch_size = 32\n",
    "n_updates = 10\n",
    "\n",
    "training_controller = TrainingController(train_steps=train_steps, clone_steps=clone_steps, batch_size=batch_size, n_batches=n_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e7792da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insufficient Sample Case: False\n",
      "Sufficient Sample Case: True\n"
     ]
    }
   ],
   "source": [
    "print('Insufficient Sample Case:', training_controller.has_samples(1))\n",
    "print('Sufficient Sample Case:', training_controller.has_samples(1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9405ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Needed Case: True\n",
      "Cloning Needed Case: True\n"
     ]
    }
   ],
   "source": [
    "print('Training Needed Case:', training_controller.should_train())\n",
    "print('Cloning Needed Case:', training_controller.should_clone_q())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff4a6615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Not Needed Case: False\n",
      "Cloning Not Needed Case: False\n"
     ]
    }
   ],
   "source": [
    "training_controller.step_increment()\n",
    "print('Training Not Needed Case:', training_controller.should_train())\n",
    "print('Cloning Not Needed Case:', training_controller.should_clone_q())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64537c01",
   "metadata": {},
   "source": [
    "# Prior Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a571a1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4997, -1.0601, -0.8653,  ...,  0.8653,  1.0601,  1.4997],\n",
       "        [-1.4997, -1.0601, -0.8653,  ...,  0.8653,  1.0601,  1.4997],\n",
       "        [-1.4997, -1.0601, -0.8653,  ...,  0.8653,  1.0601,  1.4997],\n",
       "        ...,\n",
       "        [-1.4997, -1.0601, -0.8653,  ...,  0.8653,  1.0601,  1.4997],\n",
       "        [-1.4997, -1.0601, -0.8653,  ...,  0.8653,  1.0601,  1.4997],\n",
       "        [-1.4997, -1.0601, -0.8653,  ...,  0.8653,  1.0601,  1.4997]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_measure = PriorStudentDistribution(device=device)\n",
    "support = prior_measure.sample_from_support(batch_size)\n",
    "support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cefe08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support.device.type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfa8d8f",
   "metadata": {},
   "source": [
    "# Duality HQ Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3ce49da",
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_rate = 0.99\n",
    "delta = 1e-4\n",
    "sinkhorn_radius = 0.003\n",
    "duality_operator = DualityHQOperator(discount_rate=discount_rate, delta=delta, sinkhorn_radius=sinkhorn_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8a13cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Output: tensor([[0.4561, 0.0919, 0.1363, 0.3344, 0.4668],\n",
      "        [0.5399, 0.6378, 0.7873, 0.5294, 0.1902],\n",
      "        [0.3020, 0.1753, 0.7027, 0.4825, 0.3270],\n",
      "        [0.1787, 0.2273, 0.5994, 0.0040, 0.6672]])\n"
     ]
    }
   ],
   "source": [
    "# Example inputs\n",
    "batch_size = 4\n",
    "n_samples = 5\n",
    "\n",
    "reference_r = torch.rand((batch_size, 1))  # Reference returns, shape (batch_size, 1)\n",
    "prior_r = torch.rand((batch_size, n_samples))  # Prior returns, shape (batch_size, n_samples)\n",
    "q_max = torch.rand((batch_size, n_samples))  # Maximum Q-values, shape (batch_size, n_samples)\n",
    "not_terminal = torch.ones((batch_size), dtype=torch.bool)  # Non-terminal states, shape (batch_size, 1)\n",
    "lamda = torch.rand((batch_size))  # Lambda values, shape (batch_size, 1)\n",
    "cost = torch.rand((batch_size, n_samples))  # Cost values, shape (batch_size, n_samples)\n",
    "\n",
    "# Compute cost\n",
    "cost_output = duality_operator.compute_cost(reference_r, prior_r)\n",
    "print(\"Cost Output:\", cost_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d7c879e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cij Output: tensor([[ -18368.5254,  -20886.2168,  -16897.5938,  -10696.3711,  -23196.3008],\n",
      "        [ -61874.2695,  -93767.9609,  -40809.2148,  -97187.5469, -140172.1094],\n",
      "        [ -12975.9590,  -17403.3887,  -19746.6836,  -18188.1230,  -14593.5625],\n",
      "        [ -46192.0000,  -36694.7344,  -53319.6484,  -69326.7266,  -18421.0156]])\n"
     ]
    }
   ],
   "source": [
    "# Compute cij\n",
    "cij_output = duality_operator.compute_cij(prior_r, q_max, not_terminal, lamda, cost)\n",
    "print(\"Cij Output:\", cij_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2adde400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Expectation Output: tensor([-10697.9805, -40810.8242, -12977.5684, -18422.6250])\n"
     ]
    }
   ],
   "source": [
    "# Compute inner expectation\n",
    "inner_exp_output = duality_operator.inner_expectation(cij_output)\n",
    "print(\"Inner Expectation Output:\", inner_exp_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d76179b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Sinkhorn Radius (epsilon_bar): tensor([-0.0890, -0.1874, -0.1724, -0.0011])\n"
     ]
    }
   ],
   "source": [
    "# Update Sinkhorn radius\n",
    "epsilon_bar = duality_operator.update_sinkhorn_radius(cost_output)\n",
    "print(\"Updated Sinkhorn Radius (epsilon_bar):\", epsilon_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4f4d5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HQ Value: tensor([1.3234, 3.0770, 1.4768, 1.5075])\n"
     ]
    }
   ],
   "source": [
    "# Compute HQ value\n",
    "lamda_plus = torch.log1p(torch.exp(lamda.squeeze(-1)))  # Softplus of lambda\n",
    "hq_value = duality_operator.hq_value(lamda_plus, inner_exp_output)\n",
    "print(\"HQ Value:\", hq_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99310100",
   "metadata": {},
   "source": [
    "# Optimize Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d198aae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "max_iter = 100\n",
    "step_size = 10\n",
    "gamma = 0.9\n",
    "\n",
    "lamda_from_buffer = torch.rand((batch_size), dtype=torch.float32) \n",
    "lambda_mask = torch.ones((batch_size), dtype=torch.bool)\n",
    "\n",
    "\n",
    "hq_value, lamda_star, n_iter = hq_opt_with_nn(\n",
    "    duality_operator=duality_operator,\n",
    "    reference_r=reference_r,\n",
    "    prior_r=prior_r,\n",
    "    q_max=q_max,\n",
    "    not_terminal=not_terminal,\n",
    "    lamda_from_buffer=lamda_from_buffer,\n",
    "    lambda_mask=lambda_mask,\n",
    "    lr=lr,\n",
    "    max_iter=max_iter,\n",
    "    step_size=step_size,\n",
    "    gamma=gamma\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72223f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HQ Value: tensor([ 2.3425,  1.6139, -6.3124,  1.4024])\n",
      "Optimized Lambda (lamda_star): tensor([ 0.1986,  0.7429, -0.0998,  0.2153])\n",
      "Number of Iterations: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"HQ Value:\", hq_value)\n",
    "print(\"Optimized Lambda (lamda_star):\", lamda_star)\n",
    "print(\"Number of Iterations:\", n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5a6df7",
   "metadata": {},
   "source": [
    "# Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99ee2ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Data Shapes:\n",
      "torch.Size([4, 63])\n",
      "torch.Size([4, 1])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 63])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "state_dim = 63\n",
    "action_dim = 1 #Restricted to single action using epsilon greedy\n",
    "buffer = ReplayBuffer(state_dim, action_dim, batch_size, max_len=1000, device=device)\n",
    "\n",
    "# Add data to the buffer\n",
    "state = torch.rand((batch_size, state_dim), device=device)\n",
    "action = torch.rand((batch_size, 1), device=device)\n",
    "reward = torch.rand((batch_size, 1), device=device)\n",
    "next_state = torch.rand((batch_size, state_dim), device=device)\n",
    "terminal_state = torch.zeros((batch_size, 1), dtype=torch.bool, device=device)\n",
    "lambda_val = torch.rand((batch_size, 1), device=device)\n",
    "risk_free_rate = torch.rand((batch_size, 1), device=device)\n",
    "transaction_cost = torch.rand((batch_size, 1), device=device)\n",
    "\n",
    "buffer.add(state, action, reward, next_state, terminal_state, lambda_val, risk_free_rate, transaction_cost)\n",
    "\n",
    "# Sample from the buffer\n",
    "sampled_data = buffer.sample()\n",
    "print(\"Sampled Data Shapes:\")\n",
    "for data in sampled_data:\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881afbeb",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_financial_samples(batch_size:int, device:torch.device='cpu'):\n",
    "    \"\"\"\n",
    "    Generate synthetic financial samples aligned with asset returns.\n",
    "    \n",
    "    State structure (63-dim):\n",
    "    - [0:60]: Past 60 returns\n",
    "    - [60]: Log portfolio value\n",
    "    - [61]: Current position (portfolio weight)\n",
    "    - [62]: dt (time delta)\n",
    "    \n",
    "    Inputs:\n",
    "        batch_size: Number of samples\n",
    "        device: Torch device\n",
    "    \n",
    "    Outputs:\n",
    "        Dict with keys: state, action, reward, next_state, terminal_state, \n",
    "                        lambda_val, risk_free_rate, transaction_cost\n",
    "    \"\"\"\n",
    "    # Past 60 returns (mean ~0.05%, std ~1%)\n",
    "    past_returns = torch.randn((batch_size, 60), device=device) * 0.01 + 0.0005\n",
    "    \n",
    "    # Log portfolio value (start around 0, vary Â±0.1)\n",
    "    log_portfolio_value = torch.randn((batch_size, 1), device=device) * 0.1\n",
    "    \n",
    "    # Current position/portfolio weight [0, 1]\n",
    "    current_position = torch.rand((batch_size, 1), device=device)\n",
    "    \n",
    "    # dt: time delta (daily = 1/252)\n",
    "    dt = torch.full((batch_size, 1), 1.0/252, device=device)\n",
    "    \n",
    "    # State: concatenate all components\n",
    "    state = torch.cat([past_returns, log_portfolio_value, current_position, dt], dim=1)\n",
    "    \n",
    "    # Action: portfolio weight [0, 1]\n",
    "    action = torch.rand((batch_size, 1), device=device)\n",
    "    \n",
    "    # Reward: portfolio return (realized weighted return) - shape (batch_size, 1)\n",
    "    reward = torch.randn((batch_size, 1), device=device) * 0.01 + 0.0005\n",
    "    \n",
    "    # Next_state: update components\n",
    "    next_returns = torch.randn((batch_size, 60), device=device) * 0.01 + 0.0005\n",
    "    next_log_portfolio_value = log_portfolio_value + reward\n",
    "    next_position = action\n",
    "    next_dt = torch.full((batch_size, 1), 1.0/252, device=device)\n",
    "    \n",
    "    next_state = torch.cat([next_returns, next_log_portfolio_value, next_position, next_dt], dim=1)\n",
    "    \n",
    "    # Terminal: mostly False, ~5% True - shape (batch_size,)\n",
    "    terminal_state = torch.bernoulli(torch.full((batch_size, 1), 0.05, device=device)).bool()\n",
    "    \n",
    "    # Lambda: positive values, initialized to 1.0 - shape (batch_size,)\n",
    "    lambda_val = torch.ones((batch_size, 1), device=device)\n",
    "    \n",
    "    # Risk-free rate: constant 4% (0.04/252 per day) - shape (batch_size,)\n",
    "    risk_free_rate = torch.full((batch_size, 1), 0.04/252, device=device)\n",
    "    \n",
    "    # Transaction cost: constant 0.2% (0.002) - shape (batch_size,)\n",
    "    transaction_cost = torch.full((batch_size, 1), 0.002, device=device)\n",
    "    \n",
    "    return {\n",
    "        'state': state,                    # (batch_size, 63)\n",
    "        'action': action,                  # (batch_size, 1)\n",
    "        'reward': reward,                  # (batch_size, 1)\n",
    "        'next_state': next_state,          # (batch_size, 63)\n",
    "        'terminal_state': terminal_state,  # (batch_size, 1)\n",
    "        'lambda_val': lambda_val,          # (batch_size, 1)\n",
    "        'risk_free_rate': risk_free_rate,  # (batch_size, 1)\n",
    "        'transaction_cost': transaction_cost  # (batch_size, 1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "291201c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Data Shapes:\n",
      "torch.Size([4, 63])\n",
      "torch.Size([4, 1])\n",
      "torch.Size([4, 1])\n",
      "torch.Size([4, 63])\n",
      "torch.Size([4, 1])\n",
      "torch.Size([4, 1])\n",
      "torch.Size([4, 1])\n",
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "buffer = ReplayBuffer(state_dim, action_dim, batch_size, max_len=1000, device=device)\n",
    "sampled_data = generate_financial_samples(batch_size=4, device=device)\n",
    "buffer.add(**sampled_data)\n",
    "print(\"Sampled Data Shapes:\")\n",
    "for data in sampled_data.values():\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "430536dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Data Shapes:\n",
      "torch.Size([4, 63])\n",
      "torch.Size([4, 1])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 63])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# Sample from the buffer\n",
    "sampled_data = buffer.sample()\n",
    "print(\"Sampled Data Shapes:\")\n",
    "for data in sampled_data:\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ea34eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1\n",
    "lamda_init = 1.0\n",
    "\n",
    "training_controller = TrainingController(train_steps=train_steps, clone_steps=clone_steps, batch_size=batch_size, n_batches=n_updates)\n",
    "prior_measure = PriorStudentDistribution(device=device)\n",
    "duality_operator = DualityHQOperator(discount_rate=discount_rate, delta=delta, sinkhorn_radius=sinkhorn_radius)\n",
    "\n",
    "agent = PORDQN(\n",
    "    state_dim=state_dim,\n",
    "    action_dim=action_dim,\n",
    "    batch_size=batch_size,\n",
    "    n_updates=n_updates,\n",
    "    training_controller=training_controller,\n",
    "    prior_measure=prior_measure,\n",
    "    duality_operator=duality_operator,\n",
    "    epsilon=epsilon,\n",
    "    lamda_init=lamda_init,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "552aef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions Shape: torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "observation = torch.rand((batch_size, state_dim))\n",
    "actions = agent.get_action(observation)\n",
    "print(\"Actions Shape:\", actions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c868e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch completed successfully.\n"
     ]
    }
   ],
   "source": [
    "agent.train_batch(*sampled_data)\n",
    "print(\"Training batch completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
