{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc8d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5ca0f7",
   "metadata": {},
   "source": [
    "# Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c71549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91a93813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agent_interface import *\n",
    "from src.agent import *\n",
    "from src.env import *\n",
    "from src.price_data import *\n",
    "from src.prior_measure import *\n",
    "from src.q import *\n",
    "from src.robust import *\n",
    "from src.util import *\n",
    "from src.train import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27028376",
   "metadata": {},
   "source": [
    "# Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d6e2c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '1995-01-01'\n",
    "end_date = '2024-12-31'\n",
    "batch_size = 128\n",
    "\n",
    "stock_params = {\n",
    "    'symbol': 'SPY',\n",
    "    'start_date': start_date,\n",
    "    'end_date': end_date\n",
    "}\n",
    "\n",
    "env_params = {\n",
    "    'start_date': start_date,\n",
    "    'end_date': end_date,\n",
    "    'rf_rate': 0.024,\n",
    "    'trans_cost': 0.0025,\n",
    "    'batch_size': batch_size,\n",
    "    'logging': True,\n",
    "    'seed': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5af0f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "yf = YahooFinance(**stock_params)\n",
    "df = yf.pipeline()\n",
    "asset_log_returns = df['log_return'].dropna().to_numpy()\n",
    "env = PortfolioEnv(asset_log_returns=asset_log_returns, **env_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fbb514",
   "metadata": {},
   "source": [
    "# Initialize Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c99bb0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "#Shared params\n",
    "n_updates = 1\n",
    "state_dim = 63\n",
    "action_dim = env.action_values.shape[0]\n",
    "n_epochs = 5\n",
    "\n",
    "training_controller_params = {\n",
    "    'train_steps': 1,\n",
    "    'clone_steps': 50,\n",
    "    'batch_size': batch_size,\n",
    "    'n_batches': n_updates,\n",
    "}\n",
    "\n",
    "duality_params = {\n",
    "    'discount_rate': 0.99,\n",
    "    'delta': 1e-4,\n",
    "    'sinkhorn_radius': 0.003,\n",
    "}\n",
    "\n",
    "q_params = {\n",
    "    'input_size': state_dim,\n",
    "    'hidden_size': [64, 64],\n",
    "    'output_size': action_dim\n",
    "}\n",
    "\n",
    "dqn_params = {\n",
    "    'state_dim': state_dim,\n",
    "    'action_dim': action_dim,\n",
    "    'batch_size': batch_size,\n",
    "    'n_updates': n_updates,\n",
    "    \"network_lr\": 1e-4,\n",
    "    'hq_lr': 0.02,\n",
    "    'clip_gradients': False,\n",
    "    'seed': 123\n",
    "}\n",
    "\n",
    "eps_scheduler_params = {\n",
    "    'epsilon_start': 0.9,\n",
    "    'total_timesteps': env.action_steps*n_epochs,\n",
    "    'epsilon_min': 0.1\n",
    "}\n",
    "\n",
    "other_params = {\n",
    "    \"model_name\": \"PORDQN_TRANSACTION0025_CLIPGRADIENTFALSE_EPSSCHEDULER\",\n",
    "    \"n_epochs\": n_epochs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de079181",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_controller = TrainingController(**training_controller_params)\n",
    "prior_measure = PriorStudentDistribution(device=device)\n",
    "duality_operator = DualityHQOperator(**duality_params)\n",
    "q = QFunc(**q_params)\n",
    "writer = PORDQNProgressWriter(other_params['model_name'], overwrite_existing_checkpoint_file=True)\n",
    "eps_scheduler = EpsilonGlobalScheduler(**eps_scheduler_params)\n",
    "agent = PORDQN(action_values=env.action_values, training_controller=training_controller, prior_measure=prior_measure, duality_operator=duality_operator,\n",
    "               epsilon_scheduler=eps_scheduler, qfunc=q, writer=writer, device=device, **dqn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac8ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = f\"./runs/{other_params['model_name']}/config.json\"\n",
    "params = {\n",
    "    \"stock_params\": stock_params,\n",
    "    \"env_params\": env_params, \n",
    "    \"training_controller_params\":training_controller_params,\n",
    "    \"duality_params\": duality_params,\n",
    "    \"q_params\": q_params,\n",
    "    \"dqn_params\":dqn_params,\n",
    "    \"eps_scheduler_params\": eps_scheduler_params,\n",
    "    \"other_params\": other_params\n",
    "}\n",
    "Config().download_config(params, config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2668f362",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3df6129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 1: 100%|██████████| 7491/7491 [1:40:20<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 mean of summed rewards: -99.9995%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 2: 100%|██████████| 7491/7491 [2:23:28<00:00,  1.15s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2 mean of summed rewards: -99.9968%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode 3:   0%|          | 2/7491 [00:03<3:24:02,  1.63s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m all_cum_rewards = \u001b[43mtrain_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mn_epochs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Finn_Nitro\\Documents\\GitHub\\Robustness-Test-DRO-DQN\\src\\train.py:26\u001b[39m, in \u001b[36mtrain_agent\u001b[39m\u001b[34m(env, agent, current_epoch, n_epochs, writer, checkpoint_interval)\u001b[39m\n\u001b[32m     24\u001b[39m     agent.agent_end(reward=reward, observation=next_state, info=info)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     action_idx = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43magent_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreward\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     29\u001b[39m     writer.save_model_params_periodically(epoch, agent, checkpoint_interval=checkpoint_interval)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Finn_Nitro\\Documents\\GitHub\\Robustness-Test-DRO-DQN\\src\\agent_interface.py:28\u001b[39m, in \u001b[36mAgentInterface.agent_step\u001b[39m\u001b[34m(self, reward, observation, info)\u001b[39m\n\u001b[32m     25\u001b[39m action = \u001b[38;5;28mself\u001b[39m.get_action(observation)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training_mode:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_mode_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIS_TERMINAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Update previous state and action\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mself\u001b[39m.prev_state = observation\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Finn_Nitro\\Documents\\GitHub\\Robustness-Test-DRO-DQN\\src\\agent.py:543\u001b[39m, in \u001b[36mPORDQN.train_mode_actions\u001b[39m\u001b[34m(self, reward, observation, is_terminal, info)\u001b[39m\n\u001b[32m    541\u001b[39m     \u001b[38;5;28mself\u001b[39m.clone_q()\n\u001b[32m    542\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sufficient_samples \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training_controller.should_train(): \n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate_q\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Finn_Nitro\\Documents\\GitHub\\Robustness-Test-DRO-DQN\\src\\agent.py:339\u001b[39m, in \u001b[36mPORDQN.update_q\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28mself\u001b[39m.q_updates += \u001b[32m1\u001b[39m\n\u001b[32m    338\u001b[39m states, actions, rewards, next_state, terminal_states, lambda_vals, risk_free_rates, transaction_costs, buffer_idx = \u001b[38;5;28mself\u001b[39m.buffer.sample()\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterminal_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrisk_free_rates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransaction_costs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Finn_Nitro\\Documents\\GitHub\\Robustness-Test-DRO-DQN\\src\\agent.py:475\u001b[39m, in \u001b[36mPORDQN.train_batch\u001b[39m\u001b[34m(self, states, actions, rewards, next_state, terminal_states, lambda_vals, risk_free_rates, transaction_costs, buffer_idx)\u001b[39m\n\u001b[32m    472\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m epsilon_bar.lt(\u001b[32m0\u001b[39m).any():\n\u001b[32m    473\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWarning: Sinkhorn radius is negative for some batches.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m hq_value, lamda_star, n_iter = \u001b[43mhq_opt_with_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mduality_operator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_return\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_return_from_prior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards_from_prior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimal_q_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnot_terminal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhq_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhq_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhq_max_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhq_step_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhq_gamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    477\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.compute_loss_and_update(states, actions, hq_value, mask)\n\u001b[32m    478\u001b[39m \u001b[38;5;28mself\u001b[39m._cache_lambdas(lamda_star, buffer_idx, mask)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Finn_Nitro\\Documents\\GitHub\\Robustness-Test-DRO-DQN\\src\\robust.py:247\u001b[39m, in \u001b[36mhq_opt_with_nn\u001b[39m\u001b[34m(duality_operator, reference_r, prior_r, prior_reward, q_max, not_terminal, lamda_from_buffer, lambda_mask, optimizer, lr, max_iter, step_size, gamma)\u001b[39m\n\u001b[32m    245\u001b[39m dual_obj = DualObjective(duality_operator, reference_r, prior_r, prior_reward, q_max, not_terminal)\n\u001b[32m    246\u001b[39m opt = OptimizeLamda(dual_obj, lr=lr, max_iter=max_iter, step_size=step_size, gamma=gamma)\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m lamda_star, n_iter = \u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlamda_from_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m    250\u001b[39m     hq_value = dual_obj(lamda_star)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Finn_Nitro\\Documents\\GitHub\\Robustness-Test-DRO-DQN\\src\\robust.py:201\u001b[39m, in \u001b[36mOptimizeLamda.optimize\u001b[39m\u001b[34m(self, lamda_from_buffer, lamda_mask, optimizer)\u001b[39m\n\u001b[32m    198\u001b[39m lamda_tensor = torch.stack(lamda)\n\u001b[32m    200\u001b[39m \u001b[38;5;66;03m# Compute HQ\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m hq = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdual_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlamda_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m loss = (-hq[lamda_opt]).sum()\n\u001b[32m    203\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Finn_Nitro\\Documents\\GitHub\\Robustness-Test-DRO-DQN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Finn_Nitro\\Documents\\GitHub\\Robustness-Test-DRO-DQN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "all_cum_rewards = train_agent(env, agent, 1, other_params['n_epochs'], writer=writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
